{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9004ed28",
   "metadata": {},
   "source": [
    "<h1 align='center'>Text Generation with LSTM</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "131fd076",
   "metadata": {},
   "source": [
    "In this section we will be using LSTM based deep learning model to generate texts.\n",
    "\n",
    "I will be using writing of shakespeare as a texts corpous data for traning our model.\n",
    "\n",
    "Seems exciting, Let's start building it.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc4f555a",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3177f9c3",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb963079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ajitkumarsingh/Desktop/Hands-on-with-PyTorch/Time Series Analysis with PyTorch/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55e56008",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/shakespeare.txt','r',encoding='utf8') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315939c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db295e6",
   "metadata": {},
   "source": [
    "So there are around `5.4M` characters in the above data.\n",
    "\n",
    "Let me display some lines out of the whole data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32fe9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose mi\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5576f0d",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Text data being the unstructured one is somewhat complex to deal with. Data preparation is crucial part to feed language models. \n",
    "\n",
    "We need to encode the above texts into some numbers. We are building a character level model like the prediction of the model will be a single character at each time stamp. We need to encode it on character level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df6736de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of distinct characters are : 84\n"
     ]
    }
   ],
   "source": [
    "#get all distinct characters \n",
    "\n",
    "all_char = set(text_data)\n",
    "\n",
    "print(\"Total number of distinct characters are : {}\".format(len(all_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fb948e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3e01f59",
   "metadata": {},
   "source": [
    "Let's create a encoder and decoder object. Encoder is nothing but a lookup table which return a integer value for each character in `text_data` and decoder is just opposite in the objective like it takes a integer value and return the character corresponding to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "909c0703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\" in dict(enumerate(all_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c298d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder\n",
    "\n",
    "decoder = dict(enumerate(all_char))\n",
    "\n",
    "\"\\n\" in decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff44fc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 'H'), (1, 'K'), (2, '}'), (3, 'C'), (4, ';'), (5, '('), (6, 'T'), (7, 'I'), (8, 'j'), (9, 'L'), (10, 'u'), (11, ')'), (12, 'N'), (13, 'V'), (14, 'F'), (15, '\\n'), (16, 'r'), (17, '0'), (18, 'B'), (19, 'D'), (20, 'E'), (21, '8'), (22, 'g'), (23, 'm'), (24, 'O'), (25, ','), (26, 'h'), (27, 'A'), (28, 'P'), (29, 'J'), (30, ':'), (31, 'k'), (32, 'c'), (33, '`'), (34, 'S'), (35, '6'), (36, '2'), (37, 'x'), (38, 'v'), (39, 'U'), (40, '\"'), (41, '-'), (42, 'i'), (43, 'W'), (44, 'X'), (45, '1'), (46, 's'), (47, '|'), (48, ' '), (49, 'w'), (50, '!'), (51, 'R'), (52, 'Y'), (53, 'p'), (54, '&'), (55, '5'), (56, 'Q'), (57, 'y'), (58, 'n'), (59, '['), (60, '?'), (61, '9'), (62, 'b'), (63, 'a'), (64, 'z'), (65, '3'), (66, 'e'), (67, '.'), (68, 'M'), (69, '7'), (70, 'G'), (71, 't'), (72, 'Z'), (73, 'd'), (74, \"'\"), (75, '<'), (76, 'o'), (77, '_'), (78, 'f'), (79, 'q'), (80, '4'), (81, '>'), (82, 'l'), (83, ']')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.items()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fb63134",
   "metadata": {},
   "source": [
    "Use decoderto construct encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ab775b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('H', 0), ('K', 1), ('}', 2), ('C', 3), (';', 4), ('(', 5), ('T', 6), ('I', 7), ('j', 8), ('L', 9), ('u', 10), (')', 11), ('N', 12), ('V', 13), ('F', 14), ('\\n', 15), ('r', 16), ('0', 17), ('B', 18), ('D', 19), ('E', 20), ('8', 21), ('g', 22), ('m', 23), ('O', 24), (',', 25), ('h', 26), ('A', 27), ('P', 28), ('J', 29), (':', 30), ('k', 31), ('c', 32), ('`', 33), ('S', 34), ('6', 35), ('2', 36), ('x', 37), ('v', 38), ('U', 39), ('\"', 40), ('-', 41), ('i', 42), ('W', 43), ('X', 44), ('1', 45), ('s', 46), ('|', 47), (' ', 48), ('w', 49), ('!', 50), ('R', 51), ('Y', 52), ('p', 53), ('&', 54), ('5', 55), ('Q', 56), ('y', 57), ('n', 58), ('[', 59), ('?', 60), ('9', 61), ('b', 62), ('a', 63), ('z', 64), ('3', 65), ('e', 66), ('.', 67), ('M', 68), ('7', 69), ('G', 70), ('t', 71), ('Z', 72), ('d', 73), (\"'\", 74), ('<', 75), ('o', 76), ('_', 77), ('f', 78), ('q', 79), ('4', 80), ('>', 81), ('l', 82), (']', 83)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder\n",
    "encoder = {c:i for i, c in decoder.items()}\n",
    "\n",
    "encoder.items()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4fa61bd",
   "metadata": {},
   "source": [
    "Using encoder dictionary let's encode the whole text data into corpous of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "008d8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[c] for c in text_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d327bea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 45, 15, 48, 48, 14, 16, 76, 23, 48, 78, 63, 42,\n",
       "       16, 66, 46, 71, 48, 32, 16, 66, 63, 71, 10, 16, 66, 46, 48, 49, 66,\n",
       "       48, 73, 66, 46, 42, 16, 66, 48, 42, 58, 32, 16, 66, 63, 46, 66, 25,\n",
       "       15, 48, 48,  6, 26, 63, 71, 48, 71, 26, 66, 16, 66, 62, 57, 48, 62,\n",
       "       66, 63, 10, 71, 57, 74, 46, 48, 16, 76, 46, 66, 48, 23, 42])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092b5846",
   "metadata": {},
   "source": [
    "We just converted whole text data into collection of some numbers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55a23d05",
   "metadata": {},
   "source": [
    "### Onehot encoding\n",
    "\n",
    "we need to one-hot encode our data inorder for it to work with the network structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e9f996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    '''\n",
    "    encoded_text : batch of encoded text\n",
    "    \n",
    "    num_uni_chars = number of unique characters (len(set(text)))\n",
    "    '''\n",
    "    \n",
    "    # METHOD FROM:\n",
    "    # https://stackoverflow.com/questions/29831489/convert-encoded_textay-of-indices-to-1-hot-encoded-numpy-encoded_textay\n",
    "      \n",
    "    # Create a placeholder for zeros.\n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    # Convert data type for later use with pytorch (errors if we dont!)\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "\n",
    "    # Using fancy indexing fill in the 1s at the correct index locations\n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "\n",
    "    # Reshape it so it matches the batch sahe\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "369dfe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(np.array([1,2,0]), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd1e5cc3",
   "metadata": {},
   "source": [
    "## Batch Generation\n",
    "\n",
    "We need to create a function that will generate batches of characters along with the next character in the sequence as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0664c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2321e642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 48, 48, ..., 66, 48, 23],\n",
       "       [76, 38, 66, ..., 48, 20, 12]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:-1].reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abf8d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    '''\n",
    "    Generate (using yield) batches for training.\n",
    "    \n",
    "    X: Encoded Text of length seq_len\n",
    "    Y: Encoded Text shifted by one\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    X:\n",
    "    \n",
    "    [[1 2 3]]\n",
    "    \n",
    "    Y:\n",
    "    \n",
    "    [[ 2 3 4]]\n",
    "    \n",
    "    encoded_text : Complete Encoded Text to make batches from\n",
    "    batch_size : Number of samples per batch\n",
    "    seq_len : Length of character sequence\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    # Total number of characters per batch\n",
    "    # Example: If samp_per_batch is 2 and seq_len is 50, then 100\n",
    "    # characters come out per batch.\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    \n",
    "    # Number of batches available to make\n",
    "    # Use int() to roun to nearest integer\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # Cut off end of encoded_text that\n",
    "    # won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n",
    "    \n",
    "    \n",
    "    # Reshape text into rows the size of a batch\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "    \n",
    "\n",
    "    # Go through each row in array.\n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        # Grab feature characters\n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        # y is the target shifted over by 1\n",
    "        y = np.zeros_like(x)\n",
    "       \n",
    "        #\n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1]  = encoded_text[:, n+seq_len]\n",
    "            \n",
    "        # FOR POTENTIAL INDEXING ERROR AT THE END    \n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3a17e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = encoded_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "131c1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text, samp_per_batch=2, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a9d585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[15, 48, 48, 48, 48],\n",
       "        [48, 48, 48, 48, 48]]),\n",
       " array([[48, 48, 48, 48, 48],\n",
       "        [48, 48, 48, 48, 48]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "793e5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first batch\n",
    "x, y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f850536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 48, 48, 48, 48],\n",
       "       [48, 48, 48, 48, 48]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58604acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 48, 48, 48, 48],\n",
       "       [48, 48, 48, 48, 48]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c28f64ea",
   "metadata": {},
   "source": [
    "We are done with data preparation and also we are good with batch generation for training our model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e5b7e86",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6c539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
