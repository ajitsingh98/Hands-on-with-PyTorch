{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Tabular Data with PyTorch </h1>\n",
    "\n",
    "In this notebook, I will explore PyTorch's capabilities to deal with tabular data. I will be solving a regression problem using fully connected feed forward neural networks. Then in 2nd section we will explore the models for classification problems as well. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement - Classification\n",
    "\n",
    "Here we need to perform a binary classification on the Census Income dataset available from the <a href = 'http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a><br>\n",
    "\n",
    "The goal is to determine if an individual earns more than $50K based on a set of continuous and categorical variables.\n",
    "\n",
    "### Census Income Dataset\n",
    "Here we're using the Census Income dataset available from the <a href='http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a>.\n",
    "\n",
    "The full dataset has 48,842 entries.\n",
    "\n",
    "**Here is Quick Summary of the data:**\n",
    "\n",
    "Each entry contains the following information about an individual:\n",
    "* <strong>age</strong>: the age of an individual as an integer from 18 to 90 (continuous)\n",
    "* <strong>sex</strong>: Male or Female (categorical)\n",
    "* <strong>education</strong>: represents the highest level of education achieved by an individual (categorical)\n",
    "* <strong>education_num</strong>: represents education as an integer from 3 to 16 (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>3</td><td>5th-6th</td><td>8</td><td>12th</td><td>13</td><td>Bachelors</td></tr>\n",
    "<tr><td>4</td><td>7th-8th</td><td>9</td><td>HS-grad</td><td>14</td><td>Masters</td></tr>\n",
    "<tr><td>5</td><td>9th</td><td>10</td><td>Some-college</td><td>15</td><td>Prof-school</td></tr>\n",
    "<tr><td>6</td><td>10th</td><td>11</td><td>Assoc-voc</td><td>16</td><td>Doctorate</td></tr>\n",
    "<tr><td>7</td><td>11th</td><td>12</td><td>Assoc-acdm</td></tr>\n",
    "</table></div>\n",
    "* <strong>marital-status</strong>: marital status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Married</td><td>Divorced</td><td>Married-spouse-absent</td></tr>\n",
    "<tr><td>Separated</td><td>Widowed</td><td>Never-married</td></tr>\n",
    "</table></div>\n",
    "* <strong>workclass</strong>: a general term to represent the employment status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Local-gov</td><td>Private</td></tr>\n",
    "<tr><td>State-gov</td><td>Self-emp</td></tr>\n",
    "<tr><td>Federal-gov</td></tr>\n",
    "</table></div>\n",
    "* <strong>occupation</strong>: the general type of occupation of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Adm-clerical</td><td>Handlers-cleaners</td><td>Protective-serv</td></tr>\n",
    "<tr><td>Craft-repair</td><td>Machine-op-inspct</td><td>Sales</td></tr>\n",
    "<tr><td>Exec-managerial</td><td>Other-service</td><td>Tech-support</td></tr>\n",
    "<tr><td>Farming-fishing</td><td>Prof-specialty</td><td>Transport-moving</td></tr>\n",
    "</table></div>\n",
    "* <strong>hours-per-week</strong>: the hours an individual has reported to work per week as an integer from 20 to 90 (continuous)\n",
    "* <strong>income</strong>: whether or not an individual makes more than \\\\$50,000 annually (label)\n",
    "* <strong>label</strong>: income represented as an integer (0: <=\\\\$50K, 1: >\\\\$50K) (optional label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: sympy in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ajitkumarsingh/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Private</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>50</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>57</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>Female</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Private</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    education  education-num marital-status    workclass  \\\n",
       "0   27    Male      HS-grad              9  Never-married      Private   \n",
       "1   47    Male      Masters             14        Married    Local-gov   \n",
       "2   59    Male      HS-grad              9       Divorced     Self-emp   \n",
       "3   38  Female  Prof-school             15  Never-married  Federal-gov   \n",
       "4   64  Female         11th              7        Widowed      Private   \n",
       "\n",
       "        occupation  hours-per-week income  label  \n",
       "0     Craft-repair              40  <=50K      0  \n",
       "1  Exec-managerial              50   >50K      1  \n",
       "2   Prof-specialty              20  <=50K      0  \n",
       "3   Prof-specialty              57   >50K      1  \n",
       "4  Farming-fishing              40  <=50K      0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'education', 'education-num', 'marital-status',\n",
       "       'workclass', 'occupation', 'hours-per-week', 'income', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "In the whole data we have around 10 columns. We need to seggregate columns into predictors and response categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'education', 'education-num', 'marital-status',\n",
       "       'workclass', 'occupation', 'hours-per-week', 'income', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['age', 'sex', 'education', 'education-num', 'marital-status', 'workclass', 'occupation', 'hours-per-week']\n",
    "\n",
    "response = ['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have dropped `income` feature while relevant features since `label` and `income` both are saying same thing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictor subspace is : (30000, 8)\n",
      "Shape of response subspace is : (30000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df[predictors]\n",
    "y = df[response]\n",
    "\n",
    "print(f\"Shape of predictor subspace is : {X.shape}\")\n",
    "print(f\"Shape of response subspace is : {y.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding\n",
    "\n",
    "Most of machine learning models can't handle categorical data directly. We need to encode them into numeric values before feeding them to models. The conversion of categorical values into some numeric ones is called encoding.\n",
    "\n",
    "For encoding purpose I will be using `Embedding` layers of PyTorch.\n",
    "\n",
    "Let's divide selected features into categorical and numerical class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response attribute is already in numeric mode so we will not encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "sex               object\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "workclass         object\n",
       "occupation        object\n",
       "hours-per-week     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do have bunch of categorical columns and numeric ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'education', 'marital-status', 'workclass', 'occupation']\n",
    "\n",
    "cont_cols = ['age', 'hours-per-week']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If have only 2 numeric measures and 5 categorical measures. We can directly feed numeric values but we have to separately deal with categorical values.\n",
    "\n",
    "`Pandas` provide efficient ways to deal with categorical varibale. To leverage this functionality the measures should be of `category` type.\n",
    "\n",
    "Let's typecast them into `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_cols:\n",
    "    X.loc[:, cat_col] = X.loc[:, cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  int64\n",
       "sex               category\n",
       "education         category\n",
       "education-num        int64\n",
       "marital-status    category\n",
       "workclass         category\n",
       "occupation        category\n",
       "hours-per-week       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Private</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   sex education  education-num marital-status  workclass  \\\n",
       "0   27  Male   HS-grad              9  Never-married    Private   \n",
       "1   47  Male   Masters             14        Married  Local-gov   \n",
       "\n",
       "        occupation  hours-per-week  \n",
       "0     Craft-repair              40  \n",
       "1  Exec-managerial              50  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use `series.cat.codes` and `series.cats.categories` to get encoded codes and original values over categorical features now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "29995    1\n",
       "29996    1\n",
       "29997    1\n",
       "29998    0\n",
       "29999    1\n",
       "Length: 30000, dtype: int8"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['sex'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Female', 'Male'], dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['sex'].cat.categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets divide the predictor space into categorical and numerical subspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of numeric subspace is : (30000, 2)\n",
      "Shape of categorical subspace is : (30000, 5)\n"
     ]
    }
   ],
   "source": [
    "X_cont = X[cont_cols]\n",
    "\n",
    "X_cat = X[cat_cols]\n",
    "\n",
    "print(f\"Shape of numeric subspace is : {X_cont.shape}\")\n",
    "print(f\"Shape of categorical subspace is : {X_cat.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set embedding size\n",
    "\n",
    "- I am using embedding layers provided by `torch.nn.Embedding(ni, nf)` to get encoded values for categorical columns.\n",
    "- We need to decide embedding size. \n",
    "- The size of the embedding layer can be anything but here I will be using number of distinct categories to decide embedding size of that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'education', 'marital-status', 'workclass', 'occupation']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14, 6, 5, 12]\n"
     ]
    }
   ],
   "source": [
    "#distinct categories for each attribute\n",
    "cat_szs = [len(X_cat[cat_col].cat.categories) for cat_col in cat_cols]\n",
    "print(cat_szs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these distinct categories we can deduce the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 14, 6, 5, 12]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (14, 7), (6, 3), (5, 3), (12, 6)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_szs = [(cat_sz, min((cat_sz+1)//2,50)) for cat_sz in cat_szs]\n",
    "\n",
    "emb_szs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have put upper limit of 50 on embedding size because if we have embedding of high dimension it gonna make whole computation quite expensive despite having little or no effect on performance.\n",
    "\n",
    "We will be using these embedding dimension in modeling part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformations\n",
    "\n",
    "We are done with feature selection and feature encoding now we need to transform values in proper manner and with proper data type so that we can feed them to models.\n",
    "\n",
    "PyTorch ask to convert values into tenors before doing any operations over them.\n",
    "\n",
    "Let's do that"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert conts values into tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 40.],\n",
       "        [47., 50.],\n",
       "        [59., 20.],\n",
       "        ...,\n",
       "        [47., 55.],\n",
       "        [32., 40.],\n",
       "        [33., 60.]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts = torch.tensor(X_cont.values, dtype=torch.float32)\n",
    "conts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have converted values in `torch.float32` because we will be using normalization layer and it works well on floating data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert cats values in tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10,  3,  2,  1],\n",
       "       [ 1, 11,  1,  1,  2],\n",
       "       [ 1, 10,  0,  3,  7],\n",
       "       ...,\n",
       "       [ 1, 12,  1,  2,  7],\n",
       "       [ 0, 13,  3,  2,  0],\n",
       "       [ 1,  6,  1,  3,  2]], dtype=int8)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_codes = [X_cat[col].cat.codes.values for col in cat_cols]\n",
    "\n",
    "#stack these code such that they represent a row in the original data\n",
    "cats_codes = np.stack(cats_codes, 1)\n",
    "\n",
    "cats_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 10,  3,  2,  1],\n",
       "        [ 1, 11,  1,  1,  2],\n",
       "        [ 1, 10,  0,  3,  7],\n",
       "        ...,\n",
       "        [ 1, 12,  1,  2,  7],\n",
       "        [ 0, 13,  3,  2,  0],\n",
       "        [ 1,  6,  1,  3,  2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type cast into tensors\n",
    "cats = torch.tensor(cats_codes, dtype=torch.int32)\n",
    "cats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert label into tenosrs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      1\n",
       "2      0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(y.values, dtype=torch.int64).flatten()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a classifciation problem so the labels are categorical and the encoded values should be integer instead of floating values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 8)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total size\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 30,000 examples and we can adopt `75:15:10` division for traning, validation and test splits. We will be applying this division across predictors and labels both. In above sections we seggregated the predictors based on their data type mainly into `cats` and `conts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : torch.Size([22500, 2])\n",
      "Test size : torch.Size([3000, 2])\n",
      "Validation size : torch.Size([4500, 2])\n"
     ]
    }
   ],
   "source": [
    "total_size = X.shape[0]\n",
    "\n",
    "train_size = int(total_size*0.75)\n",
    "valid_size = int(total_size*0.15)\n",
    "test_size = total_size - train_size - valid_size\n",
    "\n",
    "#get train data\n",
    "conts_train = conts[:train_size]\n",
    "cats_train = cats[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "#get validation size\n",
    "cats_valid = cats[train_size:train_size+valid_size]\n",
    "conts_valid = conts[train_size:train_size+valid_size]\n",
    "y_valid = y[train_size:train_size+valid_size]\n",
    "\n",
    "#get test size\n",
    "cats_test = cats[train_size+valid_size:total_size]\n",
    "conts_test = conts[train_size+valid_size:total_size]\n",
    "y_test = y[train_size+valid_size:total_size]\n",
    "\n",
    "print(f\"Train size : {conts_train.shape}\")\n",
    "print(f\"Test size : {conts_test.shape}\")\n",
    "print(f\"Validation size : {conts_valid.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Since we are done with all kind of preprocessing that one should performed before feeding the values to neural networks. It's time to build a model wich can take the input and come up with possible classes.\n",
    "\n",
    "Since we are working with Tabular Data, I will be using Linear layers and for categorical columns Embedding Layer is preferable before feeding them to Linear layers.\n",
    "\n",
    "Since this is a classification problem and only two values are possible either `0` and `1`, I am gonna use `nn.CrossEntropyLoss(y_pred, y_true)` as loss functions.\n",
    "\n",
    "For updating the parameters after backpropagation, I am using `torch.optim.Adam(model.parameters(), lr=lr)` as a optimizer.\n",
    "\n",
    "Final Model Structures:\n",
    "\n",
    "1. Embedding layer to get embeddings corresponding to categorical codes.\n",
    "2. A batch normalization layer for continous variables.\n",
    "3. Cancat categorical embeddings and normalized values of continous values\n",
    "4. A Linear layer having dimension of (input_size, 100)\n",
    "5. Relu activation function\n",
    "6. Dropout layer(p=0.4)\n",
    "7. A linear layer having dimension of (100, 50)\n",
    "8. Relu activation function\n",
    "9. Dropout layer(p=0.4)\n",
    "10. A sigmoid function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a class for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, layers, out_sz, p=0.5):\n",
    "        super().__init__()\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        self.embd_layer = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "        n_emb = sum([nf for ni, nf in emb_szs])\n",
    "        n_in = n_cont+n_emb\n",
    "        layerslist = []\n",
    "\n",
    "        for layer_size in layers:\n",
    "            layerslist.append(nn.Linear(n_in, layer_size))\n",
    "            layerslist.append(nn.ReLU(inplace=True))\n",
    "            layerslist.append(nn.Dropout1d(p))\n",
    "            n_in = layer_size\n",
    "        #append sigmoid function as well\n",
    "        layerslist.append(nn.Linear(layers[-1], out_sz))\n",
    "        self.resultant_struct = nn.Sequential(*layerslist)\n",
    "\n",
    "    \n",
    "    def forward(self, conts, cats):\n",
    "        embeddings = []\n",
    "        for i, emb in enumerate(self.embd_layer):\n",
    "            embeddings.append(emb(cats[:, i]))\n",
    "        cats = torch.cat(embeddings, 1)\n",
    "        #batch normalization for conts\n",
    "        conts = self.bn_cont(conts)\n",
    "        #concat both in single variable X\n",
    "        X = torch.cat([conts, cats], 1)\n",
    "\n",
    "        return self.resultant_struct(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CrossEntropyLoss` function in PyTorch combines the softmax/sigmoid function with the cross entropy calculation, so we don’t need any activation function at the output layer of our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**set the manusal seed to make outcome reproducible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8979543d30>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an instance of above model class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Classifier(emb_szs, conts.shape[1], [50], 2, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (embd_layer): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(14, 7)\n",
       "    (2): Embedding(6, 3)\n",
       "    (3): Embedding(5, 3)\n",
       "    (4): Embedding(12, 6)\n",
       "  )\n",
       "  (resultant_struct): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout1d(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss functions and optimizer\n",
    "\n",
    "Here we are using `nn.CrossEntropyLoss()` as a loss function and `torch.optim.Adam()` as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's Traning\n",
    "\n",
    "We are done with modelsing part now it's time to show some data to model and reduce it's biasness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22500])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.74205756\n",
      "epoch:  26  loss: 0.56145668\n",
      "epoch:  51  loss: 0.50201505\n",
      "epoch:  76  loss: 0.46742755\n",
      "epoch: 101  loss: 0.45239389\n",
      "epoch: 126  loss: 0.44007245\n",
      "epoch: 151  loss: 0.43061072\n",
      "epoch: 176  loss: 0.42192248\n",
      "epoch: 201  loss: 0.41536188\n",
      "epoch: 226  loss: 0.41635925\n",
      "epoch: 251  loss: 0.40426815\n",
      "epoch: 276  loss: 0.40543133\n",
      "epoch: 300  loss: 0.40311489\n",
      "\n",
      "Duration: 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    #set model in train mode\n",
    "    model.train()\n",
    "    i+=1\n",
    "    y_pred = model(conts_train, cats_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "    #validation loss\n",
    "    #set model in eval mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_valid_pred = model(conts_valid, cats_valid)\n",
    "        valid_loss = criterion(y_valid_pred, y_valid)\n",
    "        valid_losses.append(valid_loss.item())\n",
    "    \n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loss vs Validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(valid_losses, label=\"valid\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cross entropy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.29200649\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_pred = model(conts_test, cats_test)\n",
    "    loss = criterion(y_pred, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
